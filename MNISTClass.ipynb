{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5cac889-0fc0-46a0-b013-ea08a06be332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b8f009-aaae-4d7f-9abc-6ea6a3fc6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6cd334-72a4-4acc-9e12-6e07bba18bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e60b37-f1a3-47cd-90c6-47f64cb44f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888dfc22-ccac-4052-9ab4-5ed53f6389c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n",
      "4\n",
      "1\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d701bfa-650b-4e83-b9f3-941e6c005950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945ae834-3406-48d1-aae4-3e59fca2592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewImage(x,y):\n",
    "    trans = torchvision.transforms.ToPILImage()\n",
    "    plt.matshow(x)\n",
    "    plt.show()\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b625eed0-5fd0-4f80-a0d5-4569ab06b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val=23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6335e91-4871-4715-9329-5e4402ea2c2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m viewImage(train_images[val],train_labels[val])\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mviewImage\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mviewImage\u001b[39m(x,y):\n\u001b[0;32m      2\u001b[0m     trans \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToPILImage()\n\u001b[1;32m----> 3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mmatshow(x)\n\u001b[0;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:2673\u001b[0m, in \u001b[0;36mmatshow\u001b[1;34m(A, fignum, **kwargs)\u001b[0m\n\u001b[0;32m   2669\u001b[0m     ax \u001b[38;5;241m=\u001b[39m gca()\n\u001b[0;32m   2670\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2671\u001b[0m     \u001b[38;5;66;03m# Extract actual aspect ratio of array and make appropriately sized\u001b[39;00m\n\u001b[0;32m   2672\u001b[0m     \u001b[38;5;66;03m# figure.\u001b[39;00m\n\u001b[1;32m-> 2673\u001b[0m     fig \u001b[38;5;241m=\u001b[39m figure(fignum, figsize\u001b[38;5;241m=\u001b[39mfigaspect(A))\n\u001b[0;32m   2674\u001b[0m     ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_axes((\u001b[38;5;241m0.15\u001b[39m, \u001b[38;5;241m0.09\u001b[39m, \u001b[38;5;241m0.775\u001b[39m, \u001b[38;5;241m0.775\u001b[39m))\n\u001b[0;32m   2675\u001b[0m im \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mmatshow(A, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\figure.py:3706\u001b[0m, in \u001b[0;36mfigaspect\u001b[1;34m(arg)\u001b[0m\n\u001b[0;32m   3704\u001b[0m \u001b[38;5;66;03m# Extract the aspect ratio of the array\u001b[39;00m\n\u001b[0;32m   3705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isarray:\n\u001b[1;32m-> 3706\u001b[0m     nr, nc \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   3707\u001b[0m     arr_ratio \u001b[38;5;241m=\u001b[39m nr \u001b[38;5;241m/\u001b[39m nc\n\u001b[0;32m   3708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "viewImage(train_images[val],train_labels[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7960e15-3b01-438f-930b-4fa65bcd3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=torch.tensor(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "136f9ce5-69d1-40e3-a0cb-37f562084a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images.view(60000,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8972497-c80d-4484-97b7-a6075ec6526a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb138593-44dc-47cc-8a14-329148f188e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural(nn.Module):\n",
    "    def __init__():\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
