{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "985bff5e-55e3-4d23-8bbb-ce0e719a6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split \n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00b775a-a944-4987-a2b3-560fa4c6be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "855041fe-df58-4e4f-a588-39d1174baaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor())\n",
    "test_data= datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecdbd064-a341-473e-bc98-62e90817260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load=torch.utils.data.DataLoader(dataset=train_data,batch_size=1000,shuffle=True)\n",
    "test_load=torch.utils.data.DataLoader(dataset=test_data,batch_size=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa9c854-1caf-461e-b9b1-d4adf02f666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(node, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2308d3cb-2a92-4127-b4f3-4179c72bdfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = node()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d2ce29-7aa5-4d7f-98ff-e46f56ef3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6889a384-d3a9-4d08-876b-e955dab503de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for loop 0 loss is 2.3049581050872803\n",
      " for loop 1 loss is 6.0979838371276855\n",
      " for loop 2 loss is 2.6887102127075195\n",
      " for loop 3 loss is 2.2874104976654053\n",
      " for loop 4 loss is 2.296189069747925\n",
      " for loop 5 loss is 2.2817933559417725\n",
      " for loop 6 loss is 2.244628429412842\n",
      " for loop 7 loss is 2.168532371520996\n",
      " for loop 8 loss is 2.0762507915496826\n",
      " for loop 9 loss is 1.8418183326721191\n",
      " for loop 10 loss is 1.5740128755569458\n",
      " for loop 11 loss is 1.2199742794036865\n",
      " for loop 12 loss is 0.887757420539856\n",
      " for loop 13 loss is 0.7391120195388794\n",
      " for loop 14 loss is 0.592476487159729\n",
      " for loop 15 loss is 0.5854935050010681\n",
      " for loop 16 loss is 0.6191180348396301\n",
      " for loop 17 loss is 0.5231968760490417\n",
      " for loop 18 loss is 0.5314329266548157\n",
      " for loop 19 loss is 0.5261539220809937\n",
      " for loop 20 loss is 0.4870451092720032\n",
      " for loop 21 loss is 0.4626319110393524\n",
      " for loop 22 loss is 0.3893029987812042\n",
      " for loop 23 loss is 0.3183366358280182\n",
      " for loop 24 loss is 0.3808688223361969\n",
      " for loop 25 loss is 0.3297773003578186\n",
      " for loop 26 loss is 0.34968969225883484\n",
      " for loop 27 loss is 0.3110511302947998\n",
      " for loop 28 loss is 0.2739221155643463\n",
      " for loop 29 loss is 0.398264080286026\n",
      " for loop 30 loss is 0.3012354373931885\n",
      " for loop 31 loss is 0.30000245571136475\n",
      " for loop 32 loss is 0.29282501339912415\n",
      " for loop 33 loss is 0.2859976291656494\n",
      " for loop 34 loss is 0.24367159605026245\n",
      " for loop 35 loss is 0.25565463304519653\n",
      " for loop 36 loss is 0.2815209925174713\n",
      " for loop 37 loss is 0.23563218116760254\n",
      " for loop 38 loss is 0.21597084403038025\n",
      " for loop 39 loss is 0.2176133543252945\n",
      " for loop 40 loss is 0.2156822383403778\n",
      " for loop 41 loss is 0.18902643024921417\n",
      " for loop 42 loss is 0.24263642728328705\n",
      " for loop 43 loss is 0.2170938104391098\n",
      " for loop 44 loss is 0.20108862221240997\n",
      " for loop 45 loss is 0.17697829008102417\n",
      " for loop 46 loss is 0.18262912333011627\n",
      " for loop 47 loss is 0.18691474199295044\n",
      " for loop 48 loss is 0.17911186814308167\n",
      " for loop 49 loss is 0.1902087777853012\n",
      " for loop 50 loss is 0.12334202975034714\n",
      " for loop 51 loss is 0.1615682691335678\n",
      " for loop 52 loss is 0.182417631149292\n",
      " for loop 53 loss is 0.1514410674571991\n",
      " for loop 54 loss is 0.14023682475090027\n",
      " for loop 55 loss is 0.14798226952552795\n",
      " for loop 56 loss is 0.11859404295682907\n",
      " for loop 57 loss is 0.1502162218093872\n",
      " for loop 58 loss is 0.13788723945617676\n",
      " for loop 59 loss is 0.16468830406665802\n",
      "Epoch [0], Loss: 0.7313\n",
      " for loop 0 loss is 0.15020054578781128\n",
      " for loop 1 loss is 0.1131758838891983\n",
      " for loop 2 loss is 0.1554599404335022\n",
      " for loop 3 loss is 0.13008466362953186\n",
      " for loop 4 loss is 0.1269233375787735\n",
      " for loop 5 loss is 0.118700310587883\n",
      " for loop 6 loss is 0.09841566532850266\n",
      " for loop 7 loss is 0.13592810928821564\n",
      " for loop 8 loss is 0.13359205424785614\n",
      " for loop 9 loss is 0.10506388545036316\n",
      " for loop 10 loss is 0.13525371253490448\n",
      " for loop 11 loss is 0.10111789405345917\n",
      " for loop 12 loss is 0.13340431451797485\n",
      " for loop 13 loss is 0.10153792798519135\n",
      " for loop 14 loss is 0.09948056191205978\n",
      " for loop 15 loss is 0.08926589041948318\n",
      " for loop 16 loss is 0.09478073567152023\n",
      " for loop 17 loss is 0.09911217540502548\n",
      " for loop 18 loss is 0.11280731111764908\n",
      " for loop 19 loss is 0.09697259217500687\n",
      " for loop 20 loss is 0.0884367823600769\n",
      " for loop 21 loss is 0.11776036024093628\n",
      " for loop 22 loss is 0.11949007958173752\n",
      " for loop 23 loss is 0.11374984681606293\n",
      " for loop 24 loss is 0.12448478490114212\n",
      " for loop 25 loss is 0.09317456185817719\n",
      " for loop 26 loss is 0.10253427922725677\n",
      " for loop 27 loss is 0.07559432089328766\n",
      " for loop 28 loss is 0.13583900034427643\n",
      " for loop 29 loss is 0.08974448591470718\n",
      " for loop 30 loss is 0.09985002130270004\n",
      " for loop 31 loss is 0.11077519506216049\n",
      " for loop 32 loss is 0.11897366493940353\n",
      " for loop 33 loss is 0.10980091989040375\n",
      " for loop 34 loss is 0.10515178740024567\n",
      " for loop 35 loss is 0.12436568737030029\n",
      " for loop 36 loss is 0.11160172522068024\n",
      " for loop 37 loss is 0.07750765979290009\n",
      " for loop 38 loss is 0.09333399683237076\n",
      " for loop 39 loss is 0.1038149744272232\n",
      " for loop 40 loss is 0.10164584964513779\n",
      " for loop 41 loss is 0.0893927589058876\n",
      " for loop 42 loss is 0.10212606936693192\n",
      " for loop 43 loss is 0.07964546978473663\n",
      " for loop 44 loss is 0.07899647206068039\n",
      " for loop 45 loss is 0.10105851292610168\n",
      " for loop 46 loss is 0.06935267895460129\n",
      " for loop 47 loss is 0.07365348190069199\n",
      " for loop 48 loss is 0.10630916059017181\n",
      " for loop 49 loss is 0.07667236030101776\n",
      " for loop 50 loss is 0.07955216616392136\n",
      " for loop 51 loss is 0.09850214421749115\n",
      " for loop 52 loss is 0.06850054115056992\n",
      " for loop 53 loss is 0.10105067491531372\n",
      " for loop 54 loss is 0.08200139552354813\n",
      " for loop 55 loss is 0.11301683634519577\n",
      " for loop 56 loss is 0.09748239070177078\n",
      " for loop 57 loss is 0.08683355897665024\n",
      " for loop 58 loss is 0.07527618110179901\n",
      " for loop 59 loss is 0.10308247804641724\n",
      "Epoch [1], Loss: 0.1039\n",
      " for loop 0 loss is 0.056619126349687576\n",
      " for loop 1 loss is 0.063260018825531\n",
      " for loop 2 loss is 0.0755310133099556\n",
      " for loop 3 loss is 0.08112618327140808\n",
      " for loop 4 loss is 0.049815475940704346\n",
      " for loop 5 loss is 0.09330020844936371\n",
      " for loop 6 loss is 0.07169941812753677\n",
      " for loop 7 loss is 0.07382407039403915\n",
      " for loop 8 loss is 0.07359696924686432\n",
      " for loop 9 loss is 0.06562550365924835\n",
      " for loop 10 loss is 0.07177402079105377\n",
      " for loop 11 loss is 0.07155360281467438\n",
      " for loop 12 loss is 0.06029573082923889\n",
      " for loop 13 loss is 0.07154618948698044\n",
      " for loop 14 loss is 0.0708790197968483\n",
      " for loop 15 loss is 0.04749024286866188\n",
      " for loop 16 loss is 0.059411101043224335\n",
      " for loop 17 loss is 0.08427448570728302\n",
      " for loop 18 loss is 0.06420429795980453\n",
      " for loop 19 loss is 0.054601043462753296\n",
      " for loop 20 loss is 0.05770297348499298\n",
      " for loop 21 loss is 0.06186125427484512\n",
      " for loop 22 loss is 0.06921642273664474\n",
      " for loop 23 loss is 0.04207504540681839\n",
      " for loop 24 loss is 0.09686519205570221\n",
      " for loop 25 loss is 0.06631472706794739\n",
      " for loop 26 loss is 0.05128641799092293\n",
      " for loop 27 loss is 0.06082223728299141\n",
      " for loop 28 loss is 0.07503010332584381\n",
      " for loop 29 loss is 0.06307893246412277\n",
      " for loop 30 loss is 0.11091522127389908\n",
      " for loop 31 loss is 0.09017854928970337\n",
      " for loop 32 loss is 0.06793200969696045\n",
      " for loop 33 loss is 0.055008068680763245\n",
      " for loop 34 loss is 0.07254970818758011\n",
      " for loop 35 loss is 0.04084216058254242\n",
      " for loop 36 loss is 0.05113095045089722\n",
      " for loop 37 loss is 0.07189267873764038\n",
      " for loop 38 loss is 0.05685511603951454\n",
      " for loop 39 loss is 0.05093589052557945\n",
      " for loop 40 loss is 0.06876165419816971\n",
      " for loop 41 loss is 0.060332540422677994\n",
      " for loop 42 loss is 0.07157156616449356\n",
      " for loop 43 loss is 0.07394751906394958\n",
      " for loop 44 loss is 0.06010753661394119\n",
      " for loop 45 loss is 0.06972631067037582\n",
      " for loop 46 loss is 0.06498918682336807\n",
      " for loop 47 loss is 0.07714593410491943\n",
      " for loop 48 loss is 0.074685238301754\n",
      " for loop 49 loss is 0.06500846892595291\n",
      " for loop 50 loss is 0.08458677679300308\n",
      " for loop 51 loss is 0.08063975721597672\n",
      " for loop 52 loss is 0.0882771760225296\n",
      " for loop 53 loss is 0.06491201370954514\n",
      " for loop 54 loss is 0.08083175122737885\n",
      " for loop 55 loss is 0.07555122673511505\n",
      " for loop 56 loss is 0.060630302876234055\n",
      " for loop 57 loss is 0.06587432324886322\n",
      " for loop 58 loss is 0.051484424620866776\n",
      " for loop 59 loss is 0.0693228617310524\n",
      "Epoch [2], Loss: 0.0680\n",
      " for loop 0 loss is 0.05370292067527771\n",
      " for loop 1 loss is 0.04890752583742142\n",
      " for loop 2 loss is 0.0467153824865818\n",
      " for loop 3 loss is 0.053752824664115906\n",
      " for loop 4 loss is 0.0366765558719635\n",
      " for loop 5 loss is 0.07547739148139954\n",
      " for loop 6 loss is 0.07231499999761581\n",
      " for loop 7 loss is 0.05352860316634178\n",
      " for loop 8 loss is 0.06436002254486084\n",
      " for loop 9 loss is 0.03295174241065979\n",
      " for loop 10 loss is 0.049191609025001526\n",
      " for loop 11 loss is 0.03591304272413254\n",
      " for loop 12 loss is 0.08309994637966156\n",
      " for loop 13 loss is 0.059128813445568085\n",
      " for loop 14 loss is 0.058218058198690414\n",
      " for loop 15 loss is 0.06065409630537033\n",
      " for loop 16 loss is 0.041532251983881\n",
      " for loop 17 loss is 0.06673718988895416\n",
      " for loop 18 loss is 0.05753094702959061\n",
      " for loop 19 loss is 0.06767627596855164\n",
      " for loop 20 loss is 0.05954749137163162\n",
      " for loop 21 loss is 0.05822937935590744\n",
      " for loop 22 loss is 0.047413475811481476\n",
      " for loop 23 loss is 0.07165537029504776\n",
      " for loop 24 loss is 0.04684072732925415\n",
      " for loop 25 loss is 0.07809608429670334\n",
      " for loop 26 loss is 0.0551874116063118\n",
      " for loop 27 loss is 0.053973034024238586\n",
      " for loop 28 loss is 0.03874541074037552\n",
      " for loop 29 loss is 0.061422768980264664\n",
      " for loop 30 loss is 0.06537685543298721\n",
      " for loop 31 loss is 0.046861376613378525\n",
      " for loop 32 loss is 0.04971746355295181\n",
      " for loop 33 loss is 0.06459371745586395\n",
      " for loop 34 loss is 0.03440150246024132\n",
      " for loop 35 loss is 0.04096654802560806\n",
      " for loop 36 loss is 0.047039661556482315\n",
      " for loop 37 loss is 0.07197520136833191\n",
      " for loop 38 loss is 0.052036359906196594\n",
      " for loop 39 loss is 0.05020580813288689\n",
      " for loop 40 loss is 0.037171587347984314\n",
      " for loop 41 loss is 0.048936016857624054\n",
      " for loop 42 loss is 0.05879032984375954\n",
      " for loop 43 loss is 0.0707855299115181\n",
      " for loop 44 loss is 0.0693141371011734\n",
      " for loop 45 loss is 0.07236918807029724\n",
      " for loop 46 loss is 0.05854376405477524\n",
      " for loop 47 loss is 0.027024630457162857\n",
      " for loop 48 loss is 0.06398631632328033\n",
      " for loop 49 loss is 0.025421269237995148\n",
      " for loop 50 loss is 0.04910699278116226\n",
      " for loop 51 loss is 0.051606684923172\n",
      " for loop 52 loss is 0.053820256143808365\n",
      " for loop 53 loss is 0.03781231865286827\n",
      " for loop 54 loss is 0.04971935227513313\n",
      " for loop 55 loss is 0.03646622225642204\n",
      " for loop 56 loss is 0.0748448520898819\n",
      " for loop 57 loss is 0.06643595546483994\n",
      " for loop 58 loss is 0.05979003384709358\n",
      " for loop 59 loss is 0.0667845830321312\n",
      "Epoch [3], Loss: 0.0549\n",
      " for loop 0 loss is 0.035687386989593506\n",
      " for loop 1 loss is 0.03683394566178322\n",
      " for loop 2 loss is 0.04763207584619522\n",
      " for loop 3 loss is 0.042097434401512146\n",
      " for loop 4 loss is 0.04100143536925316\n",
      " for loop 5 loss is 0.03771420940756798\n",
      " for loop 6 loss is 0.04024086892604828\n",
      " for loop 7 loss is 0.05354825034737587\n",
      " for loop 8 loss is 0.030929964035749435\n",
      " for loop 9 loss is 0.07014412432909012\n",
      " for loop 10 loss is 0.05197906866669655\n",
      " for loop 11 loss is 0.0499308705329895\n",
      " for loop 12 loss is 0.0492943711578846\n",
      " for loop 13 loss is 0.030368326231837273\n",
      " for loop 14 loss is 0.037188395857810974\n",
      " for loop 15 loss is 0.0472257025539875\n",
      " for loop 16 loss is 0.034577444195747375\n",
      " for loop 17 loss is 0.034322597086429596\n",
      " for loop 18 loss is 0.04565457999706268\n",
      " for loop 19 loss is 0.05313504487276077\n",
      " for loop 20 loss is 0.02943197451531887\n",
      " for loop 21 loss is 0.03505457565188408\n",
      " for loop 22 loss is 0.034079451113939285\n",
      " for loop 23 loss is 0.03183623403310776\n",
      " for loop 24 loss is 0.04468182846903801\n",
      " for loop 25 loss is 0.0427761934697628\n",
      " for loop 26 loss is 0.026565564796328545\n",
      " for loop 27 loss is 0.047423698008060455\n",
      " for loop 28 loss is 0.029755767434835434\n",
      " for loop 29 loss is 0.05391771346330643\n",
      " for loop 30 loss is 0.048343975096940994\n",
      " for loop 31 loss is 0.05245218798518181\n",
      " for loop 32 loss is 0.047315798699855804\n",
      " for loop 33 loss is 0.03600852191448212\n",
      " for loop 34 loss is 0.04059378057718277\n",
      " for loop 35 loss is 0.04273786023259163\n",
      " for loop 36 loss is 0.05997728183865547\n",
      " for loop 37 loss is 0.039287980645895004\n",
      " for loop 38 loss is 0.02961535006761551\n",
      " for loop 39 loss is 0.059678010642528534\n",
      " for loop 40 loss is 0.04468940198421478\n",
      " for loop 41 loss is 0.05458500236272812\n",
      " for loop 42 loss is 0.06065087020397186\n",
      " for loop 43 loss is 0.05178236588835716\n",
      " for loop 44 loss is 0.05994483828544617\n",
      " for loop 45 loss is 0.07388950139284134\n",
      " for loop 46 loss is 0.027464335784316063\n",
      " for loop 47 loss is 0.03879059478640556\n",
      " for loop 48 loss is 0.04538649693131447\n",
      " for loop 49 loss is 0.05486462265253067\n",
      " for loop 50 loss is 0.06362783163785934\n",
      " for loop 51 loss is 0.04459751024842262\n",
      " for loop 52 loss is 0.038674525916576385\n",
      " for loop 53 loss is 0.0429900586605072\n",
      " for loop 54 loss is 0.06611015647649765\n",
      " for loop 55 loss is 0.04909145459532738\n",
      " for loop 56 loss is 0.04689723253250122\n",
      " for loop 57 loss is 0.05189576372504234\n",
      " for loop 58 loss is 0.05275885760784149\n",
      " for loop 59 loss is 0.04963061213493347\n",
      "Epoch [4], Loss: 0.0453\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i,(images, labels) in enumerate(train_load):\n",
    "        images=images.cuda()\n",
    "        labels=labels.cuda()\n",
    "        outputs = model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        print(f\" for loop {i} loss is {loss}\")\n",
    "\n",
    "    print(f\"Epoch [{epoch}], Loss: {running_loss/len(train_load):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ce2b33-d709-43c6-a5d6-ed01f4e4c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 98.48%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_load:\n",
    "        images=images.cuda()\n",
    "        labels=labels.cuda()\n",
    "\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e79863-bacc-42b1-a4ff-9f5952014349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
